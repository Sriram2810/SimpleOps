{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b3000f1-b227-454e-88c3-9e8e93e9d4f2",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd9a083-605f-4483-9eed-da5d273c4525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Filter trips between 1 min and 2 hours\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d431698e-f362-49d6-b22f-06ad96335c58",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c788bdbf-4143-45e8-8a83-224aa716a2af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m df = pd.read_parquet(\u001b[33m'\u001b[39m\u001b[33m../data/yellow_tripdata_2024-01.parquet\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Yellow Taxi Project\\SimpleOps\\project\\.venv\\Lib\\site-packages\\pandas\\__init__.py:151\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcomputation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28meval\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    135\u001b[39m     concat,\n\u001b[32m    136\u001b[39m     lreshape,\n\u001b[32m   (...)\u001b[39m\u001b[32m    148\u001b[39m     qcut,\n\u001b[32m    149\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m testing\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_print_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Yellow Taxi Project\\SimpleOps\\project\\.venv\\Lib\\site-packages\\pandas\\api\\__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\" public toolkit API \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     extensions,\n\u001b[32m      4\u001b[39m     indexers,\n\u001b[32m      5\u001b[39m     interchange,\n\u001b[32m      6\u001b[39m     types,\n\u001b[32m      7\u001b[39m     typing,\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m __all__ = [\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minterchange\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mextensions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtyping\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1147\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:690\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:936\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1073\u001b[39m, in \u001b[36mget_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1130\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('../data/yellow_tripdata_2024-01.parquet')\n",
    "\n",
    "df['trip_duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds()\n",
    "\n",
    "df = df[(df['trip_duration'] >= 60) & (df['trip_duration'] <= 7200)]\n",
    "y = df['trip_duration']\n",
    "\n",
    "df['pickup_hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "df['pickup_weekday'] = df['tpep_pickup_datetime'].dt.weekday\n",
    "df['is_weekend'] = df['pickup_weekday'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Trip distance (approximate Manhattan distance)\n",
    "df['manhattan_dist'] = abs(df['PULocationID'] - df['DOLocationID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b00784-fa43-4c93-976c-ec25f3a02aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_of_day(hour):\n",
    "    if hour < 6: return 'night'\n",
    "    elif hour < 12: return 'morning'\n",
    "    elif hour < 18: return 'afternoon'\n",
    "    else: return 'evening'\n",
    "\n",
    "df['time_of_day'] = df['pickup_hour'].apply(time_of_day)\n",
    "categorical_cols = ['VendorID', 'RatecodeID', 'store_and_fwd_flag', 'time_of_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e9f952-5e4b-43a5-8dc7-362d4d456b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def prepare_features(X, categorical_cols, xgboost=False):\n",
    "    \"\"\"\n",
    "    Prepares features for ML models.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): Input DataFrame\n",
    "        categorical_cols (list): List of categorical column names\n",
    "        xgboost (bool): If True, apply label encoding (for XGBoost). If False, apply one-hot encoding (for linear/NN)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame or (pd.DataFrame, dict): \n",
    "            - If xgboost=False: returns one-hot encoded DataFrame\n",
    "            - If xgboost=True: returns label-encoded DataFrame and label encoders\n",
    "    \"\"\"\n",
    "    X_copy = X.copy()\n",
    "    \n",
    "    if xgboost:\n",
    "        label_encoders = {}\n",
    "        for col in categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            X_copy[col] = le.fit_transform(X_copy[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "        return X_copy, label_encoders\n",
    "    \n",
    "    else:\n",
    "        X_encoded = pd.get_dummies(X_copy, columns=categorical_cols, drop_first=True)\n",
    "        return X_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a75dc-399c-4189-97cf-c6056159a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[categorical_cols + ['pickup_hour', 'pickup_weekday', 'is_weekend', 'manhattan_dist',\n",
    "                           'passenger_count', 'PULocationID', 'DOLocationID']]\n",
    "X_encoded, label_encoders = prepare_features(X, categorical_cols, xgboost=True)\n",
    "\n",
    "# Normalize numerical columns\n",
    "numerical_cols = ['pickup_hour', 'pickup_weekday', 'manhattan_dist']\n",
    "X_encoded[numerical_cols] = StandardScaler().fit_transform(X_encoded[numerical_cols])\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_encoded, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0251bae-62f3-44ae-82c0-e6d03c7a53d7",
   "metadata": {},
   "source": [
    "## <b> XG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249021e-97ac-4bc0-9079-be428a2f3616",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=20,\n",
    "    eval_metric=\"rmse\"  # <- move this here\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7af1b-52a8-43db-b1a7-c8c247fccec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(X_val)\n",
    "from math import sqrt\n",
    "rmse = sqrt(mean_squared_error(y_val, y_pred))\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(f\"XGBoost Tuned - RMSE: {rmse:.2f}, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d31990-0d16-45b1-a7eb-c7fab7457cdd",
   "metadata": {},
   "source": [
    "## <b1> RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c9dc0-b004-4b9e-a46e-c4893e928c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "# Initialize the RandomForestRegressor model\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model using the training data\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c0f1cb-a7a5-4c0b-82be-5cc881d4aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the validation set\n",
    "y_pred = rf_model.predict(X_val)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "rmse = sqrt(mean_squared_error(y_val, y_pred))\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Random Forest - RMSE: {rmse:.2f}, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f4913d-ce3f-4cdf-ac51-cb885173033b",
   "metadata": {},
   "source": [
    "## <b1> SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bbf675-70b1-432d-bb29-3d1efb281aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "# Impute missing values with the mean strategy\n",
    "imputer = SimpleImputer(strategy='mean')  # You can also use 'median' or other strategies\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_val_imputed = imputer.transform(X_val)\n",
    "\n",
    "# Initialize the SVR model\n",
    "svr_model = SVR(kernel='linear', C=1, gamma='auto', epsilon=0.1)\n",
    "\n",
    "# Train the model using the training data\n",
    "svr_model.fit(X_train_imputed, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4392d796-5f99-4f45-bc37-4e0b2c672396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the validation set\n",
    "y_pred = svr_model.predict(X_val)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "rmse = sqrt(mean_squared_error(y_val, y_pred))\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"SVR - RMSE: {rmse:.2f}, R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013607d0-8e57-4002-ab6d-8840b2894f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d42147b-bb33-482c-956c-ad54ffd23c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')  # You can also use 'median' or other strategies\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_val_imputed = imputer.transform(X_val)\n",
    "\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train_imputed, y_train)\n",
    "y_pred = ridge.predict(X_val_imputed)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_val, y_pred))\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Ridge - RMSE: {rmse:.2f}, R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe733c9-57e5-403b-818d-009ae2539137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "enet = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)\n",
    "enet.fit(X_train_imputed, y_train)\n",
    "y_pred = enet.predict(X_val_imputed)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_val, y_pred))\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(f\"ElasticNet - RMSE: {rmse:.2f}, R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135e9c31-66c5-40fc-88e0-652bbb80b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd = SGDRegressor(loss='squared_error', penalty='l2', max_iter=1000, tol=1e-3, random_state=42)\n",
    "sgd.fit(X_train_imputed, y_train)\n",
    "y_pred = sgd.predict(X_val_imputed)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_val, y_pred))\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(f\"SGD Regressor - RMSE: {rmse:.2f}, R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afaa55f-a81a-4037-a5cc-eee8839bbcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "\n",
    "pa = PassiveAggressiveRegressor(random_state=42, max_iter=1000, tol=1e-3)\n",
    "pa.fit(X_train_imputed, y_train)\n",
    "y_pred = pa.predict(X_val_imputed)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_val, y_pred))\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(f\"Passive Aggressive - RMSE: {rmse:.2f}, R²: {r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finalkernel",
   "language": "python",
   "name": "finalkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
